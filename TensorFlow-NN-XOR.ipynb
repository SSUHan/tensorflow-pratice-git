{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Neural Network for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.],\n",
       "       [ 1.,  1.,  0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = np.loadtxt('train_nn_xor.txt', unpack=False)\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(x_data))\n",
    "print(len(x_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = np.reshape(xy[:, -1], (4,1))\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 먼저 Logistic Regression  으로 작업해 본다면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([len(x_data[0]), 1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = tf.matmul(X, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypo = tf.div(1. , 1. + tf.exp(-h))\n",
    "# hypo = tf.sigmoid(h) 를 풀어쓰면 위와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y*tf.log(hypo) + (1-Y)*tf.log(1-hypo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "cost :  0.731819\n",
      "[[-0.72030699]\n",
      " [-0.13553387]]\n",
      "==================================================\n",
      "step :  200\n",
      "cost :  0.693611\n",
      "[[-0.09440705]\n",
      " [ 0.07432526]]\n",
      "==================================================\n",
      "step :  400\n",
      "cost :  0.693183\n",
      "[[-0.02431148]\n",
      " [ 0.02385534]]\n",
      "==================================================\n",
      "step :  600\n",
      "cost :  0.69315\n",
      "[[-0.00687833]\n",
      " [ 0.00686797]]\n",
      "==================================================\n",
      "step :  800\n",
      "cost :  0.693147\n",
      "[[-0.00196162]\n",
      " [ 0.00196138]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for step in range(1000):\n",
    "    sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(\"step : \", step)\n",
    "        print(\"cost : \", sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "        print(sess.run(W))\n",
    "        print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrent_prediction = tf.equal(tf.floor(hypo + 0.5), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(corrent_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypo : \n",
      " [[ 0.5       ]\n",
      " [ 0.50014079]\n",
      " [ 0.49985912]\n",
      " [ 0.5       ]]\n",
      "floor : \n",
      " [[ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]]\n",
      "corrent_prediction : \n",
      " [[False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]]\n",
      "accuracy : \n",
      " 0.25\n"
     ]
    }
   ],
   "source": [
    "print(\"hypo : \\n\", sess.run(hypo, feed_dict={X:x_data, Y:y_data}))\n",
    "print(\"floor : \\n\", sess.run(tf.floor(hypo+0.5), feed_dict={X:x_data, Y:y_data}))\n",
    "print(\"corrent_prediction : \\n\", sess.run(corrent_prediction, feed_dict={X:x_data, Y:y_data}))\n",
    "print(\"accuracy : \\n\", sess.run(accuracy, feed_dict={X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론 : Logistic Regression 으로는 이론적으로도 실질적으로도 0.5 이상 나올 수가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그렇다면, Layer 를 한개 더 둠으로써, NN 을 이용해서 구해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_uniform([2,2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([2,1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Layer2\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Hypo Function\n",
    "hypo = tf.sigmoid(tf.matmul(L2, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Cost Function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypo) + (1-Y)*tf.log(1. - hypo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "alpha = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "cost :  0.840066\n",
      "W1 : \n",
      " [[ 0.3595995  -0.13043241 -0.1837099  -0.23773938  0.00861581  0.57257885\n",
      "   0.77715933  0.05348545  0.89103347  0.96544778]\n",
      " [ 0.85606402  0.79053497  0.55438542 -0.8337965   0.04768913 -0.57149667\n",
      "  -0.50974476  0.99481124  0.89738971  0.04536261]]\n",
      "W2 : \n",
      " [[-0.46030766]\n",
      " [-0.96081531]\n",
      " [ 0.60846549]\n",
      " [-0.68036109]\n",
      " [-0.59672469]\n",
      " [ 0.62184668]\n",
      " [-0.36329108]\n",
      " [-0.56613868]\n",
      " [-0.04485464]\n",
      " [ 0.33153325]]\n",
      "============================================================\n",
      "step :  2000\n",
      "cost :  0.419411\n",
      "W1 : \n",
      " [[ 0.28312019 -0.39471865 -1.11333168 -2.28917933  0.45707017  0.49649289\n",
      "   2.41550422 -0.14644633  3.00679588  1.1011939 ]\n",
      " [ 0.87833893  1.63204575  0.25580126 -2.4157331   0.28779396 -1.50417733\n",
      "  -1.20941222  1.3746171   3.04136539  0.7189784 ]]\n",
      "W2 : \n",
      " [[-0.66880953]\n",
      " [-1.45461786]\n",
      " [ 1.20022202]\n",
      " [-2.24934864]\n",
      " [-0.7094807 ]\n",
      " [ 1.337111  ]\n",
      " [-2.02765512]\n",
      " [-0.97450948]\n",
      " [ 3.25888014]\n",
      " [ 0.31411639]]\n",
      "============================================================\n",
      "step :  4000\n",
      "cost :  0.0603702\n",
      "W1 : \n",
      " [[ 0.53501052 -1.32142425 -2.48544598 -3.45974398  0.81918103  1.62729454\n",
      "   4.82078171 -0.35056531  4.58083916  1.20929515]\n",
      " [ 1.2757498   3.33765674  0.65280747 -3.49347258  0.64187753 -3.49015594\n",
      "  -3.07571268  2.32041931  4.58064699  0.91578442]]\n",
      "W2 : \n",
      " [[-1.37093282]\n",
      " [-2.96194625]\n",
      " [ 2.76947594]\n",
      " [-3.53464937]\n",
      " [-1.11909974]\n",
      " [ 3.70925593]\n",
      " [-5.18192291]\n",
      " [-1.87726557]\n",
      " [ 6.15254927]\n",
      " [ 0.5318948 ]]\n",
      "============================================================\n",
      "step :  6000\n",
      "cost :  0.022763\n",
      "W1 : \n",
      " [[ 0.68995094 -1.71199358 -3.0624218  -3.72898626  0.9349252   2.13690972\n",
      "   5.40683794 -0.44139147  4.9310317   1.2541424 ]\n",
      " [ 1.38369167  3.86540389  0.95114863 -3.76506329  0.7329554  -4.14762354\n",
      "  -3.608289    2.633641    4.94325447  0.99443203]]\n",
      "W2 : \n",
      " [[-1.63180971]\n",
      " [-3.53639412]\n",
      " [ 3.45390391]\n",
      " [-3.89211965]\n",
      " [-1.29251564]\n",
      " [ 4.67124605]\n",
      " [-6.27512264]\n",
      " [-2.14526176]\n",
      " [ 6.9838829 ]\n",
      " [ 0.69306928]]\n",
      "============================================================\n",
      "step :  8000\n",
      "cost :  0.0130537\n",
      "W1 : \n",
      " [[ 0.79258204 -1.91914845 -3.37399602 -3.85718155  1.0015074   2.40379357\n",
      "   5.67620373 -0.49451888  5.09382343  1.28070855]\n",
      " [ 1.4399631   4.12198925  1.13609469 -3.89595509  0.78517532 -4.46294785\n",
      "  -3.85882306  2.7971487   5.11272478  1.03930855]]\n",
      "W2 : \n",
      " [[-1.78748035]\n",
      " [-3.84684277]\n",
      " [ 3.84541249]\n",
      " [-4.06739378]\n",
      " [-1.39755106]\n",
      " [ 5.19092131]\n",
      " [-6.82968283]\n",
      " [-2.28499746]\n",
      " [ 7.39571381]\n",
      " [ 0.78913689]]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "    sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 2000 == 0:\n",
    "        print(\"step : \", step)\n",
    "        print(\"cost : \", sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "        print(\"W1 : \\n\", sess.run(W1, feed_dict={X:x_data, Y:y_data}))\n",
    "        print(\"W2 : \\n\", sess.run(W2, feed_dict={X:x_data, Y:y_data}))\n",
    "        print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test NN Model\n",
    "corrent_prediction = tf.equal(tf.floor(hypo + 0.5), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(corrent_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypo : \n",
      " [[ 0.0037942 ]\n",
      " [ 0.99040473]\n",
      " [ 0.99099052]\n",
      " [ 0.01305356]]\n",
      "floor : \n",
      " [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]]\n",
      "corrent_prediction : \n",
      " [[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "accuracy : \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check Accuracy\n",
    "print(\"hypo : \\n\", sess.run(hypo, feed_dict={X:x_data, Y:y_data}))\n",
    "print(\"floor : \\n\", sess.run(tf.floor(hypo+0.5), feed_dict={X:x_data, Y:y_data}))\n",
    "print(\"corrent_prediction : \\n\", sess.run(corrent_prediction, feed_dict={X:x_data, Y:y_data}))\n",
    "print(\"accuracy : \\n\", sess.run(accuracy, feed_dict={X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론 : NN Model 로 정확도 1.0 을 얻어냈다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Wide\" Neural Network for XOR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wide Neural Network 는 레이어를 구성할때, 더 많은 뉴런들로 구성하는 것을 말합니다.\n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Hypo Fuction\n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypo = tf.sigmoid( tf.matmul(L2,W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypo)+(1-Y)* tf.log(1.-hypo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize cost.\n",
    "alpha = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "cost :  0.917693\n",
      "W1 : \n",
      " [[-0.22265865  0.05458229 -0.11917987 -0.48066619 -0.55019432  0.58600932\n",
      "  -0.58177257  0.68136412  0.4146634   0.81032532]\n",
      " [ 0.0077646  -0.86452949  0.20272186  0.11087734 -0.05062024 -0.30531913\n",
      "   0.10912818  0.7315492  -0.45006469  0.85396051]]\n",
      "W2 : \n",
      " [[ 0.08631957]\n",
      " [ 0.09290914]\n",
      " [-0.40912399]\n",
      " [ 0.05123728]\n",
      " [ 0.48107508]\n",
      " [-0.77188593]\n",
      " [ 0.62754953]\n",
      " [ 0.86122894]\n",
      " [ 0.92806929]\n",
      " [ 0.67687917]]\n",
      "============================================================\n",
      "step :  2000\n",
      "cost :  0.339809\n",
      "W1 : \n",
      " [[-0.00403753  0.04456377 -0.13380773 -0.23492903 -0.69496322  3.05959845\n",
      "  -0.91268748  2.73229694  1.25980496  2.98526096]\n",
      " [ 0.35557896 -1.01806474  1.29845202  0.46704116 -0.16122191 -1.85186052\n",
      "  -0.02098741  2.6164813  -2.4075861   2.86862612]]\n",
      "W2 : \n",
      " [[-0.55768949]\n",
      " [ 0.47413841]\n",
      " [-1.73288274]\n",
      " [-0.53204358]\n",
      " [ 0.37765852]\n",
      " [-3.29862022]\n",
      " [ 0.56611151]\n",
      " [ 2.37675905]\n",
      " [ 2.2396009 ]\n",
      " [ 2.72405124]]\n",
      "============================================================\n",
      "step :  4000\n",
      "cost :  0.0481751\n",
      "W1 : \n",
      " [[ 0.27473295 -0.00993435 -0.6543768   0.02882234 -0.92435902  5.264575\n",
      "  -1.25306845  3.6297462   2.79924011  3.96918154]\n",
      " [ 0.74691576 -1.42477989  2.58699417  0.91563857 -0.29016769 -3.72578454\n",
      "  -0.06560961  3.57191825 -4.4627409   3.91474438]]\n",
      "W2 : \n",
      " [[-0.95971549]\n",
      " [ 1.21584404]\n",
      " [-2.84803104]\n",
      " [-0.91579628]\n",
      " [ 0.92909175]\n",
      " [-6.75322342]\n",
      " [ 1.17662001]\n",
      " [ 3.681252  ]\n",
      " [ 5.05750418]\n",
      " [ 4.24380302]]\n",
      "============================================================\n",
      "step :  6000\n",
      "cost :  0.0211933\n",
      "W1 : \n",
      " [[ 0.37081933 -0.0420023  -0.89360696  0.10366581 -1.05344558  5.83299446\n",
      "  -1.43701625  3.85882688  3.26065707  4.21261549]\n",
      " [ 0.82991105 -1.56290817  3.02912903  1.02475607 -0.30713388 -4.21979952\n",
      "  -0.03363074  3.84591389 -5.00981903  4.20426083]]\n",
      "W2 : \n",
      " [[-1.09121466]\n",
      " [ 1.46888101]\n",
      " [-3.23204255]\n",
      " [-1.03196669]\n",
      " [ 1.18326211]\n",
      " [-8.00200367]\n",
      " [ 1.47078967]\n",
      " [ 4.0970006 ]\n",
      " [ 6.02562094]\n",
      " [ 4.71052742]]\n",
      "============================================================\n",
      "step :  8000\n",
      "cost :  0.0130602\n",
      "W1 : \n",
      " [[ 0.4264535  -0.06233346 -1.04890847  0.14298838 -1.13974059  6.12103128\n",
      "  -1.56094873  3.98049474  3.50530052  4.34036207]\n",
      " [ 0.86886674 -1.64041746  3.27787185  1.07953095 -0.31223556 -4.47332382\n",
      "  -0.00902871  3.99168825 -5.28818655  4.35636282]]\n",
      "W2 : \n",
      " [[-1.170748  ]\n",
      " [ 1.61471808]\n",
      " [-3.46450949]\n",
      " [-1.0998385 ]\n",
      " [ 1.3403914 ]\n",
      " [-8.70631123]\n",
      " [ 1.65523517]\n",
      " [ 4.32717514]\n",
      " [ 6.56852198]\n",
      " [ 4.96641016]]\n",
      "============================================================\n",
      "step :  10000\n",
      "cost :  0.00928675\n",
      "W1 : \n",
      " [[ 0.46546528 -0.07716322 -1.16417289  0.16886154 -1.20456839  6.30660963\n",
      "  -1.6545577   4.06190109  3.6676302   4.4252429 ]\n",
      " [ 0.89296079 -1.69358075  3.44756532  1.11492443 -0.31477249 -4.63858557\n",
      "   0.00964231  4.08854437 -5.46834469  4.45671701]]\n",
      "W2 : \n",
      " [[-1.22854424]\n",
      " [ 1.71646893]\n",
      " [-3.63284111]\n",
      " [-1.1482228 ]\n",
      " [ 1.45388782]\n",
      " [-9.18828487]\n",
      " [ 1.78920376]\n",
      " [ 4.4842267 ]\n",
      " [ 6.94064474]\n",
      " [ 5.14008522]]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 2000 == 0:\n",
    "        print(\"step : \", step)\n",
    "        print(\"cost : \", sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "        print(\"W1 : \\n\", sess.run(W1))\n",
    "        print(\"W2 : \\n\", sess.run(W2))\n",
    "        print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test wide NN Model\n",
    "correct_prediction = tf.equal(tf.floor(hypo + 0.5), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypo : \n",
      " [[ 0.00416614]\n",
      " [ 0.98976058]\n",
      " [ 0.99152911]\n",
      " [ 0.01407304]]\n",
      "floor : \n",
      " [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]]\n",
      "corrent_prediction : \n",
      " [[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "accuracy : \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check Accuracy\n",
    "print(\"hypo : \\n\", sess.run(hypo, feed_dict={X:x_data, Y:y_data}))\n",
    "print(\"floor : \\n\", sess.run(tf.floor(hypo+0.5), feed_dict={X:x_data, Y:y_data}))\n",
    "print(\"corrent_prediction : \\n\", sess.run(correct_prediction, feed_dict={X:x_data, Y:y_data}))\n",
    "print(\"accuracy : \\n\", sess.run(accuracy, feed_dict={X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론 : wide 하게 Neural 을 만들면서 cost 가 엄청나게 줄어든 모습을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
