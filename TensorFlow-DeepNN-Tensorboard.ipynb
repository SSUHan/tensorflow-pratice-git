{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Deep\" Neural Network with XOR problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  1.]]\n",
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('train_nn_xor.txt', unpack=False)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = np.reshape(xy[:, -1], (4,1))\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name=\"X-input\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y-input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0),name = 'weight1')\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0),name = 'weight2')\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0),name = 'weight3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1 = tf.Variable(tf.zeros([5]), name=\"bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"bias3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Histogram Summary\n",
    "w1_histo = tf.histogram_summary(\"weight1\", W1)\n",
    "w2_histo = tf.histogram_summary(\"weight2\", W2)\n",
    "w3_histo = tf.histogram_summary(\"weight3\", W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Scalar Summary\n",
    "b1_histo = tf.histogram_summary(\"biases1\", b1)\n",
    "b2_histo = tf.histogram_summary(\"biases2\", b2)\n",
    "b3_histo = tf.histogram_summary(\"biases3\", b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_histo = tf.histogram_summary(\"place_y\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Scope with Hypothesis\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    L2 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "with tf.name_scope(\"layer3\") as scope:\n",
    "    L3 = tf.sigmoid(tf.matmul(L2, W2) + b2)\n",
    "\n",
    "with tf.name_scope(\"layer4\") as scope:\n",
    "    hypo = tf.sigmoid(tf.matmul(L3, W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Cost Function with scope\n",
    "with tf.name_scope(\"cost_function\") as scope:\n",
    "    cost = -tf.reduce_mean(Y*tf.log(hypo) + (1-Y)*tf.log(1. - hypo))\n",
    "    cost_scar = tf.scalar_summary(\"cost\", cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Train Logic with scope\n",
    "alpha = tf.Variable(0.1)\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "    train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "cost :  0.76108\n",
      "W1 : \n",
      " [[ 0.01974434 -0.99958456  0.02618453  0.85854793 -0.07320779]\n",
      " [-0.92627096  0.3410019   0.59965938 -0.6505     -0.82240695]]\n",
      "W2 : \n",
      " [[ 0.04008046 -0.82403541 -0.66884452  0.05348672]\n",
      " [ 0.66839582 -0.70012367  0.38191846 -0.50685328]\n",
      " [-0.3316125  -0.86369973  0.41306058 -0.48190263]\n",
      " [-0.50960767 -0.85956419 -0.40235081  0.88436371]\n",
      " [-0.09054393 -0.25807095 -0.26899168  0.4191457 ]]\n",
      "W3 : \n",
      " [[ 0.0680053 ]\n",
      " [-0.9725486 ]\n",
      " [-0.89077693]\n",
      " [-0.43748528]]\n",
      "============================================================\n",
      "step :  2000\n",
      "cost :  0.692301\n",
      "W1 : \n",
      " [[ 0.1356919  -1.15567648 -0.00182854  0.75413841 -0.05813748]\n",
      " [-0.93517154  0.43642408  0.59414715 -0.68951225 -0.81310099]]\n",
      "W2 : \n",
      " [[ 0.0270965  -0.83572924 -0.64208782  0.0863625 ]\n",
      " [ 0.70616478 -0.84274101  0.27125862 -0.53248334]\n",
      " [-0.32236186 -0.88244617  0.39513165 -0.46248803]\n",
      " [-0.52767515 -0.80637413 -0.34016913  0.93285567]\n",
      " [-0.11310515 -0.26283908 -0.22649026  0.45976824]]\n",
      "W3 : \n",
      " [[ 0.36118576]\n",
      " [-0.9482953 ]\n",
      " [-0.59997243]\n",
      " [-0.35442325]]\n",
      "============================================================\n",
      "step :  4000\n",
      "cost :  0.688199\n",
      "W1 : \n",
      " [[ 0.29157889 -1.54506218 -0.05610558  0.73924166 -0.05210078]\n",
      " [-1.07531095  0.74112517  0.54093158 -0.76915526 -0.84092009]]\n",
      "W2 : \n",
      " [[ 0.01726641 -0.86889559 -0.64386147  0.16135629]\n",
      " [ 0.82437086 -1.01689959  0.14233981 -0.65916389]\n",
      " [-0.33313066 -0.78872287  0.42948839 -0.40463442]\n",
      " [-0.55196792 -0.75547469 -0.31626141  1.04801452]\n",
      " [-0.15850927 -0.25452855 -0.18202719  0.55572456]]\n",
      "W3 : \n",
      " [[ 0.5889954 ]\n",
      " [-1.14065516]\n",
      " [-0.54501516]\n",
      " [-0.54122066]]\n",
      "============================================================\n",
      "step :  6000\n",
      "cost :  0.525406\n",
      "W1 : \n",
      " [[ 1.26995361 -3.26773882 -0.19906603  0.90777415 -0.04307118]\n",
      " [-1.95371985  2.67006898  0.42890483 -1.06572711 -0.95841295]]\n",
      "W2 : \n",
      " [[ 0.59343731 -1.55856895 -0.95049012  0.22084399]\n",
      " [ 1.89385748 -2.00229263 -0.44635162 -1.70838153]\n",
      " [-0.47051418 -0.14428601  0.48673406 -0.31064525]\n",
      " [-0.33811101 -0.80566847 -0.44438612  1.3433646 ]\n",
      " [-0.17452474 -0.14188582 -0.20193221  0.77969331]]\n",
      "W3 : \n",
      " [[ 2.06139779]\n",
      " [-2.67169118]\n",
      " [-0.89788002]\n",
      " [-1.21699357]]\n",
      "============================================================\n",
      "step :  8000\n",
      "cost :  0.0206765\n",
      "W1 : \n",
      " [[ 3.79049587 -4.80052137 -0.55159336  1.18934608 -0.16054435]\n",
      " [-4.05165815  4.64270401  0.69666833 -1.47137976 -0.96753329]]\n",
      "W2 : \n",
      " [[ 3.16264963 -3.96908665 -1.87255013 -0.23024449]\n",
      " [ 3.40094256 -4.12612295 -1.40744376 -2.60057211]\n",
      " [-1.0683341   0.50101513  0.6712712  -0.22724283]\n",
      " [ 0.27418259 -1.0983932  -0.55275291  1.40644586]\n",
      " [-0.30746782  0.2316404  -0.08251675  0.90477979]]\n",
      "W3 : \n",
      " [[ 5.45761633]\n",
      " [-6.26502037]\n",
      " [-2.24940658]\n",
      " [-1.81582272]]\n",
      "============================================================\n",
      "step :  10000\n",
      "cost :  0.00761693\n",
      "W1 : \n",
      " [[ 4.11740112 -5.04961443 -0.58066916  1.22247207 -0.19717672]\n",
      " [-4.36957026  4.9011817   0.74818665 -1.53756487 -0.96779174]]\n",
      "W2 : \n",
      " [[ 3.59057689 -4.33408499 -2.06464672 -0.35604638]\n",
      " [ 3.76751852 -4.52319717 -1.63877594 -2.72376442]\n",
      " [-1.16737914  0.56743801  0.70472336 -0.20948824]\n",
      " [ 0.33157501 -1.13035715 -0.56449586  1.38697541]\n",
      " [-0.36797592  0.29492077 -0.0477915   0.91291803]]\n",
      "W3 : \n",
      " [[ 6.23308945]\n",
      " [-6.97217607]\n",
      " [-2.54730964]\n",
      " [-1.92973924]]\n",
      "============================================================\n",
      "hypo : \n",
      " [[ 0.00760939]\n",
      " [ 0.99313402]\n",
      " [ 0.99050272]\n",
      " [ 0.00637648]]\n",
      "floor : \n",
      " [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]]\n",
      "correct_prediction : \n",
      " [[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "accuracy : \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    # Marge Summaries\n",
    "    merged = tf.merge_all_summaries()\n",
    "    writer = tf.train.SummaryWriter('./tensorboard/DeepNN2', sess.graph)\n",
    "    \n",
    "    # init variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 2000 == 0:\n",
    "            print(\"step : \", step)\n",
    "            print(\"cost : \", sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "            print(\"W1 : \\n\", sess.run(W1))\n",
    "            print(\"W2 : \\n\", sess.run(W2))\n",
    "            print(\"W3 : \\n\", sess.run(W3))\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            summary = sess.run(merged, feed_dict={X:x_data, Y:y_data})\n",
    "            writer.add_summary(summary, step)\n",
    "        \n",
    "    \n",
    "    # Test Model\n",
    "    correct_prediction = tf.equal(tf.floor(hypo + 0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "    \n",
    "    # Check Accuracy\n",
    "    print(\"hypo : \\n\", sess.run(hypo, feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"floor : \\n\", sess.run(tf.floor(hypo+0.5), feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"correct_prediction : \\n\", sess.run(correct_prediction, feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"accuracy : \\n\", sess.run(accuracy, feed_dict={X:x_data, Y:y_data}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch tensorboard \n",
    "* tensorboard --logdir=your tensorboard file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
