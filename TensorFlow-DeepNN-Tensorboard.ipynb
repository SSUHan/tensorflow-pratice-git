{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Deep\" Neural Network with XOR problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  1.]]\n",
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('train_nn_xor.txt', unpack=False)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = np.reshape(xy[:, -1], (4,1))\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name=\"X-input\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y-input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0),name = 'weight1')\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0),name = 'weight2')\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0),name = 'weight3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1 = tf.Variable(tf.zeros([5]), name=\"bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"bias3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Histogram Summary\n",
    "w1_histo = tf.histogram_summary(\"weight1\", W1)\n",
    "w2_histo = tf.histogram_summary(\"weight2\", W2)\n",
    "w3_histo = tf.histogram_summary(\"weight3\", W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Scalar Summary\n",
    "b1_histo = tf.histogram_summary(\"biases1\", b1)\n",
    "b2_histo = tf.histogram_summary(\"biases2\", b2)\n",
    "b3_histo = tf.histogram_summary(\"biases3\", b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_histo = tf.histogram_summary(\"place_y\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Scope with Hypothesis\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    L2 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "with tf.name_scope(\"layer3\") as scope:\n",
    "    L3 = tf.sigmoid(tf.matmul(L2, W2) + b2)\n",
    "\n",
    "with tf.name_scope(\"layer4\") as scope:\n",
    "    hypo = tf.sigmoid(tf.matmul(L3, W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Cost Function with scope\n",
    "with tf.name_scope(\"cost_function\") as scope:\n",
    "    cost = -tf.reduce_mean(Y*tf.log(hypo) + (1-Y)*tf.log(1. - hypo))\n",
    "    cost_scar = tf.scalar_summary(\"cost\", cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Train Logic with scope\n",
    "alpha = tf.Variable(0.1)\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "    train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step :  0\n",
      "cost :  0.697454\n",
      "W1 : \n",
      " [[-0.32017502  0.9640075  -0.22153488  0.42467871 -0.78454638]\n",
      " [ 0.12175141  0.29855728  0.13210329  0.69192827 -0.84961689]]\n",
      "W2 : \n",
      " [[ 0.52003384  0.19968994  0.67923504 -0.00841916]\n",
      " [-0.22266243 -0.74752688  0.397753    0.61091894]\n",
      " [-0.00541555 -0.35958916  0.99465752 -0.08501495]\n",
      " [-0.29192007 -0.44530201  0.84550834  0.69162631]\n",
      " [ 0.94730109  0.65942025 -0.36853722 -0.0107594 ]]\n",
      "W3 : \n",
      " [[ 0.68633747]\n",
      " [ 0.38644731]\n",
      " [ 0.32227474]\n",
      " [-0.98085344]]\n",
      "============================================================\n",
      "step :  2000\n",
      "cost :  0.692965\n",
      "W1 : \n",
      " [[-0.27486765  0.88891554 -0.1583562   0.29977921 -0.65714955]\n",
      " [ 0.14361     0.06179487  0.1580472   0.57834083 -0.73394376]]\n",
      "W2 : \n",
      " [[ 0.55401647  0.19787358  0.64442545  0.00829354]\n",
      " [-0.15028018 -0.71091747  0.45434186  0.5002234 ]\n",
      " [ 0.02850897 -0.35914567  0.96700114 -0.07507259]\n",
      " [-0.22212718 -0.4083465   0.88319558  0.57014483]\n",
      " [ 0.87291861  0.59125638 -0.50443006  0.27797732]]\n",
      "W3 : \n",
      " [[ 0.42654756]\n",
      " [ 0.03713532]\n",
      " [ 0.50209278]\n",
      " [-0.92343885]]\n",
      "============================================================\n",
      "step :  4000\n",
      "cost :  0.690821\n",
      "W1 : \n",
      " [[-0.22369882  0.92938077 -0.05395116  0.36219031 -0.85805887]\n",
      " [ 0.16642599  0.02798466  0.21843587  0.60524058 -0.91769302]]\n",
      "W2 : \n",
      " [[ 0.57585043  0.19522768  0.60518342 -0.00333594]\n",
      " [-0.13506703 -0.7188316   0.53088444  0.47300923]\n",
      " [ 0.04722662 -0.36275572  0.94466186 -0.08700083]\n",
      " [-0.2020974  -0.42012197  0.95001376  0.50307715]\n",
      " [ 0.8419832   0.61658418 -0.74332476  0.49653181]]\n",
      "W3 : \n",
      " [[ 0.26983303]\n",
      " [-0.19320047]\n",
      " [ 0.77053177]\n",
      " [-0.97847962]]\n",
      "============================================================\n",
      "step :  6000\n",
      "cost :  0.64156\n",
      "W1 : \n",
      " [[-0.12111133  1.10196543  0.16059358  0.74357241 -2.09303093]\n",
      " [ 0.2464512   0.23855859  0.38400179  0.91482818 -2.1108532 ]]\n",
      "W2 : \n",
      " [[ 0.58313143  0.17572562  0.49329057 -0.09188931]\n",
      " [-0.12889539 -0.74921072  0.67085469  0.50653374]\n",
      " [ 0.05430474 -0.38375124  0.90052021 -0.12716064]\n",
      " [-0.1941226  -0.49584523  1.16707802  0.44538379]\n",
      " [ 0.82932031  0.98700446 -1.95235181  1.14919758]]\n",
      "W3 : \n",
      " [[-0.19396259]\n",
      " [-0.74896479]\n",
      " [ 1.85464346]\n",
      " [-1.52731836]]\n",
      "============================================================\n",
      "step :  8000\n",
      "cost :  0.33162\n",
      "W1 : \n",
      " [[-0.19172321  1.71986258  0.42120147  1.20381856 -4.41265345]\n",
      " [ 0.06512674  1.05483961  0.55299556  1.57007229 -4.34162331]]\n",
      "W2 : \n",
      " [[ 0.56907064 -0.03492472  0.79464471 -0.70891613]\n",
      " [ 0.38606405 -0.59148842  1.35057437  2.24778104]\n",
      " [ 0.21596593 -0.49172223  1.35008752 -0.03540048]\n",
      " [ 0.26580751 -0.50364286  2.16246557  1.8091476 ]\n",
      " [ 1.01369309  1.719486   -4.43327475  2.17924523]]\n",
      "W3 : \n",
      " [[-0.91811293]\n",
      " [-0.9222005 ]\n",
      " [ 3.94971466]\n",
      " [-4.48061991]]\n",
      "============================================================\n",
      "step :  10000\n",
      "cost :  0.0297214\n",
      "W1 : \n",
      " [[-0.39433506  2.46099639  0.71078008  1.99822176 -5.13718033]\n",
      " [-0.25211266  2.33182645  0.76875013  2.20492029 -5.06556177]]\n",
      "W2 : \n",
      " [[ 0.24382579 -0.17982392  0.96807855 -1.39749205]\n",
      " [ 0.9197557  -0.43559611  1.65282607  4.34138393]\n",
      " [ 0.00656417 -0.63643968  1.78229213 -0.27133587]\n",
      " [ 0.71145451 -0.38969415  2.50016689  3.59735417]\n",
      " [ 1.24857593  1.98796129 -5.2288599   3.95098925]]\n",
      "W3 : \n",
      " [[-1.54957521]\n",
      " [-0.99247354]\n",
      " [ 5.50841761]\n",
      " [-8.54282856]]\n",
      "============================================================\n",
      "hypo : \n",
      " [[ 0.01149842]\n",
      " [ 0.96946108]\n",
      " [ 0.9691776 ]\n",
      " [ 0.04400082]]\n",
      "floor : \n",
      " [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]]\n",
      "correct_prediction : \n",
      " [[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "accuracy : \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    # Marge Summaries\n",
    "    merged = tf.merge_all_summaries()\n",
    "    writer = tf.train.SummaryWriter('./tensorboard/DeepNN', sess.graph)\n",
    "    \n",
    "    # init variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 2000 == 0:\n",
    "            print(\"step : \", step)\n",
    "            print(\"cost : \", sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "            print(\"W1 : \\n\", sess.run(W1))\n",
    "            print(\"W2 : \\n\", sess.run(W2))\n",
    "            print(\"W3 : \\n\", sess.run(W3))\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            summary = sess.run(merged, feed_dict={X:x_data, Y:y_data})\n",
    "            writer.add_summary(summary, step)\n",
    "        \n",
    "    \n",
    "    # Test Model\n",
    "    correct_prediction = tf.equal(tf.floor(hypo + 0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "    \n",
    "    # Check Accuracy\n",
    "    print(\"hypo : \\n\", sess.run(hypo, feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"floor : \\n\", sess.run(tf.floor(hypo+0.5), feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"correct_prediction : \\n\", sess.run(correct_prediction, feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"accuracy : \\n\", sess.run(accuracy, feed_dict={X:x_data, Y:y_data}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch tensorboard \n",
    "* tensorboard --logdir=your tensorboard file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
